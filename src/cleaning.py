"""
Fun√ß√µes de limpeza e pipeline de transforma√ß√£o para dados do WhatsApp.

Uso:
    from cleaning import run_pipeline, CLEANING_STEPS
    
    result = run_pipeline(
        order=['u200e', 'empty_timestamps', 'anonymize'],
        raw_file=Path('raw-data.txt'),
        output_dir=Path('data/interim')
    )
"""

import re
from pathlib import Path
from utils import audit_transformation, audit_pipeline


# =============================================================================
# FUN√á√ïES DE TRANSFORMA√á√ÉO
# Cada fun√ß√£o recebe (input_file, output_file) e retorna dict com m√©tricas
# =============================================================================

def remove_u200e(input_file, output_file):
    """
    Remove todas as ocorr√™ncias do caractere invis√≠vel U+200E.
    
    O caractere U+200E (Left-to-Right Mark) √© inserido pelo WhatsApp durante
    a exporta√ß√£o para controle de dire√ß√£o de texto, mas n√£o carrega informa√ß√£o
    sem√¢ntica √∫til para an√°lise.
    """
    invisible_char = '\u200e'
    total = 0
    
    with open(input_file, 'r', encoding='utf-8') as f_in:
        with open(output_file, 'w', encoding='utf-8') as f_out:
            for line in f_in:
                total += line.count(invisible_char)
                f_out.write(line.replace(invisible_char, ''))
    
    return {'caracteres_removidos': total}


def remove_empty_timestamps(input_file, output_file):
    """
    Remove timestamps vazios seguidos de m√∫ltiplas m√≠dias consecutivas.
    
    Quando m√∫ltiplas m√≠dias s√£o enviadas simultaneamente, o WhatsApp registra
    uma linha com timestamp e remetente vazios, seguida das m√≠dias. A primeira
    linha √© redundante e pode ser removida.
    """
    timestamp_pattern = r'^\[\d{2}/\d{2}/\d{2}, \d{2}:\d{2}:\d{2}\]'
    media_patterns = [
        '<attached:', 'audio omitted', 'image omitted', 'video omitted', 
        'sticker omitted', 'GIF omitted', 'document omitted'
    ]
    
    lines = open(input_file, 'r', encoding='utf-8').readlines()
    skip = set()
    
    for i in range(len(lines) - 2):
        curr = lines[i].strip()
        next1 = lines[i + 1].strip()
        next2 = lines[i + 2].strip()
        
        if (re.match(timestamp_pattern, curr) and curr.endswith(':') and 
            re.match(timestamp_pattern, next1)):
            has_media_next = any(p in next1 for p in media_patterns)
            has_media_next2 = (re.match(timestamp_pattern, next2) and 
                               any(p in next2 for p in media_patterns))
            
            if has_media_next and has_media_next2:
                skip.add(i)
    
    cleaned = [l for i, l in enumerate(lines) if i not in skip]
    open(output_file, 'w', encoding='utf-8').writelines(cleaned)
    
    return {'linhas_removidas': len(skip)}


def remove_empty_lines(input_file, output_file):
    """
    Remove linhas completamente vazias.
    
    Linhas que cont√™m apenas \\n n√£o carregam informa√ß√£o e podem ser removidas
    para reduzir o tamanho do arquivo.
    """
    lines = open(input_file, 'r', encoding='utf-8').readlines()
    cleaned = [l for l in lines if l != '\n']
    open(output_file, 'w', encoding='utf-8').writelines(cleaned)
    
    return {'linhas_removidas': len(lines) - len(cleaned)}


def normalize_whitespace(input_file, output_file):
    """
    Normaliza espa√ßos em branco internos, preservando indenta√ß√£o.
    
    - M√∫ltiplos espa√ßos consecutivos ‚Üí espa√ßo √∫nico
    - Tabs ‚Üí espa√ßo √∫nico
    - Trailing whitespace ‚Üí removido
    - Indenta√ß√£o inicial ‚Üí preservada (tratada em etapa separada)
    """
    lines = open(input_file, 'r', encoding='utf-8').readlines()
    cleaned = []
    
    for line in lines:
        line = line.rstrip() + '\n'
        indent = len(line) - len(line.lstrip())
        content = line[indent:].replace('\t', ' ')
        content = re.sub(r' {2,}', ' ', content)
        cleaned.append(line[:indent] + content)
    
    open(output_file, 'w', encoding='utf-8').writelines(cleaned)
    
    orig_size = sum(len(l.encode('utf-8')) for l in lines)
    clean_size = sum(len(l.encode('utf-8')) for l in cleaned)
    
    return {'bytes_economizados': orig_size - clean_size}


def anonymize_participants(input_file, output_file):
    """
    Substitui nomes dos participantes por identificadores an√¥nimos.
    
    Mapeamento padr√£o:
    - Marlon ‚Üí P1
    - L√™ üñ§ ‚Üí P2
    """
    mapping = {'Marlon': 'P1', 'L√™ üñ§': 'P2'}
    
    lines = open(input_file, 'r', encoding='utf-8').readlines()
    result = []
    counts = {k: 0 for k in mapping}
    
    for line in lines:
        for name, anon in mapping.items():
            if f'] {name}:' in line:
                line = line.replace(f'] {name}:', f'] {anon}:')
                counts[name] += 1
        result.append(line)
    
    open(output_file, 'w', encoding='utf-8').writelines(result)
    
    return {'substituicoes': counts}


def optimize_timestamps(input_file, output_file):
    """
    Remove delimitadores redundantes do timestamp.
    
    Transforma: [28/11/24, 19:30:05] P1: Mensagem
    Em:         28/11/24 19:30:05 P1: Mensagem
    
    Economiza 4 caracteres por mensagem e facilita o parsing.
    """
    pattern = r'^\[(\d{2}/\d{2}/\d{2}), (\d{2}:\d{2}:\d{2})\]'
    
    lines = open(input_file, 'r', encoding='utf-8').readlines()
    result = []
    count = 0
    
    for line in lines:
        match = re.match(pattern, line)
        if match:
            result.append(f"{match.group(1)} {match.group(2)}" + line[len(match.group(0)):])
            count += 1
        else:
            result.append(line)
    
    open(output_file, 'w', encoding='utf-8').writelines(result)
    
    return {'timestamps_otimizados': count}


def normalize_indentation(input_file, output_file):
    """
    Remove indenta√ß√£o de linhas de continua√ß√£o.
    
    Mensagens multilinha frequentemente cont√™m espa√ßos de indenta√ß√£o no in√≠cio
    das linhas de continua√ß√£o. Esses espa√ßos s√£o visuais e n√£o carregam
    informa√ß√£o sem√¢ntica.
    """
    timestamp_pattern = r'^\d{2}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}'
    
    lines = open(input_file, 'r', encoding='utf-8').readlines()
    result = []
    spaces = 0
    
    for line in lines:
        # Se N√ÉO come√ßa com timestamp, √© linha de continua√ß√£o
        if not re.match(timestamp_pattern, line):
            orig_len = len(line)
            line = line.lstrip(' \t')
            spaces += orig_len - len(line)
        result.append(line)
    
    open(output_file, 'w', encoding='utf-8').writelines(result)
    
    return {'espacos_removidos': spaces}


# =============================================================================
# REGISTRO DE ETAPAS DISPON√çVEIS
# Cada etapa tem: id, name, function, description
# =============================================================================

CLEANING_STEPS = {
    'u200e': {
        'name': 'Remo√ß√£o U+200E',
        'function': remove_u200e,
        'description': '''O caractere `U+200E` (Left-to-Right Mark) √© um caractere de formata√ß√£o invis√≠vel 
usado para controle de dire√ß√£o de texto. O WhatsApp o insere sistematicamente 
durante a exporta√ß√£o, mas n√£o carrega informa√ß√£o sem√¢ntica √∫til.

**Impacto identificado:** ~48.700 ocorr√™ncias, ~243 KB, presente em ~50% das linhas.'''
    },
    'empty_timestamps': {
        'name': 'Remo√ß√£o timestamps vazios',
        'function': remove_empty_timestamps,
        'description': '''Quando m√∫ltiplas m√≠dias s√£o enviadas simultaneamente, o WhatsApp registra uma 
linha com timestamp vazio seguida das m√≠dias. A primeira linha √© redundante.'''
    },
    'empty_lines': {
        'name': 'Remo√ß√£o linhas vazias',
        'function': remove_empty_lines,
        'description': '''Linhas completamente vazias (apenas `\\n`) aparecem entre mensagens e n√£o 
carregam informa√ß√£o. Ser√£o removidas preservando a formata√ß√£o interna.'''
    },
    'whitespace': {
        'name': 'Normaliza√ß√£o espa√ßos',
        'function': normalize_whitespace,
        'description': '''Normaliza espa√ßos em branco internos:
- M√∫ltiplos espa√ßos ‚Üí espa√ßo √∫nico
- Tabs ‚Üí espa√ßo √∫nico  
- Trailing whitespace ‚Üí removido
- **Preserva:** Indenta√ß√£o inicial'''
    },
    'anonymize': {
        'name': 'Anonimiza√ß√£o',
        'function': anonymize_participants,
        'description': '''Substitui nomes dos participantes por identificadores gen√©ricos:
- Marlon ‚Üí P1
- L√™ üñ§ ‚Üí P2'''
    },
    'timestamps': {
        'name': 'Otimiza√ß√£o timestamps',
        'function': optimize_timestamps,
        'description': '''Remove delimitadores redundantes para facilitar o parsing:
- De: `[28/11/24, 19:30:05] P1: Mensagem`
- Para: `28/11/24 19:30:05 P1: Mensagem`'''
    },
    'indentation': {
        'name': 'Normaliza√ß√£o indenta√ß√£o',
        'function': normalize_indentation,
        'description': '''Remove espa√ßos/tabs iniciais de linhas de continua√ß√£o (mensagens multilinha).
Esses espa√ßos s√£o visuais e n√£o carregam informa√ß√£o sem√¢ntica.'''
    },
}


# =============================================================================
# EXECUTOR DO PIPELINE
# =============================================================================

def run_pipeline(order: list, raw_file: Path, output_dir: Path, show_progress: bool = True) -> dict:
    """
    Executa pipeline de limpeza na ordem especificada.
    
    Args:
        order: Lista de IDs das etapas na ordem desejada.
                Ex: ['u200e', 'anonymize', 'timestamps']
        raw_file: Path do arquivo de entrada (raw-data.txt)
        output_dir: Path do diret√≥rio para arquivos intermedi√°rios
        show_progress: Se True, imprime progresso no console
        
    Returns:
        Dict com:
        - outputs: {step_id: Path} - Caminhos dos arquivos gerados
        - audits: {step_id: dict} - Resultados das auditorias
        - metrics: {step_id: dict} - M√©tricas retornadas pelas fun√ß√µes
        - order: list - Ordem executada
        - steps: dict - Refer√™ncia para CLEANING_STEPS
        - df_audit: DataFrame - Auditoria consolidada
        - totals: dict - Totais do pipeline
        - final_output: Path - Arquivo final gerado
        
    Raises:
        ValueError: Se algum step_id n√£o existir em CLEANING_STEPS
        
    Example:
        result = run_pipeline(
            order=['u200e', 'empty_timestamps', 'anonymize'],
            raw_file=Path('data/raw/raw-data.txt'),
            output_dir=Path('data/interim')
        )
        
        # Acessa resultados
        print(result['totals']['total_percent'])  # Redu√ß√£o total %
        print(result['final_output'])  # Arquivo final
    """
    # Valida IDs
    invalid_ids = [sid for sid in order if sid not in CLEANING_STEPS]
    if invalid_ids:
        raise ValueError(f"IDs de etapa inv√°lidos: {invalid_ids}. "
                        f"Dispon√≠veis: {list(CLEANING_STEPS.keys())}")
    
    # Garante que output_dir existe
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    raw_file = Path(raw_file)
    
    outputs = {}
    audits = {}
    metrics = {}
    
    previous = raw_file
    
    if show_progress:
        print(f"üîÑ Executando pipeline com {len(order)} etapas...\n")
    
    for i, step_id in enumerate(order):
        step = CLEANING_STEPS[step_id]
        step_num = i + 1
        output_file = output_dir / f'raw-data_cln{step_num}.txt'
        
        if show_progress:
            print(f"   {step_num}. {step['name']}...", end=' ')
        
        # Executa transforma√ß√£o
        step_metrics = step['function'](previous, output_file)
        
        # Auditoria
        audit = audit_transformation(
            previous, 
            output_file, 
            step['name'],
            show_output=False
        )
        
        if show_progress:
            print(f"‚úÖ (-{audit['delta_percent']:.2f}%)")
        
        # Guarda resultados
        outputs[step_id] = output_file
        audits[step_id] = audit
        metrics[step_id] = step_metrics
        
        # Pr√≥xima etapa usa este output
        previous = output_file
    
    # Auditoria final consolidada
    stages = [{'file': str(raw_file), 'name': 'üìÑ Original (raw-data.txt)'}]
    for step_id in order:
        stages.append({
            'file': str(outputs[step_id]),
            'name': f"‚îî‚îÄ {CLEANING_STEPS[step_id]['name']}"
        })
    
    df_audit, totals = audit_pipeline(stages, show_output=False)
    
    if show_progress:
        print(f"\n‚úÖ Pipeline conclu√≠do!")
        print(f"   üì¶ Redu√ß√£o total: {totals['total_percent']:.2f}%")
        print(f"   üìÅ Arquivo final: {previous.name}")
    
    return {
        'outputs': outputs,
        'audits': audits,
        'metrics': metrics,
        'order': order,
        'steps': CLEANING_STEPS,
        'df_audit': df_audit,
        'totals': totals,
        'final_output': previous
    }


def get_available_steps() -> list:
    """
    Retorna lista de IDs de etapas dispon√≠veis.
    
    Returns:
        Lista de strings com IDs v√°lidos para usar em run_pipeline()
    """
    return list(CLEANING_STEPS.keys())


def get_step_info(step_id: str) -> dict:
    """
    Retorna informa√ß√µes sobre uma etapa espec√≠fica.
    
    Args:
        step_id: ID da etapa
        
    Returns:
        Dict com name, function, description
        
    Raises:
        KeyError: Se step_id n√£o existir
    """
    return CLEANING_STEPS[step_id]