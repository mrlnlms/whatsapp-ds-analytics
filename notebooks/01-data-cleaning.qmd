---
title: "Data Cleaning"
subtitle: "Limpeza e normaliza√ß√£o do arquivo bruto"
author: "Marlon L."
date: today
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    theme: cosmo
execute:
  warning: false
  echo: false
---

```{python}
#| label: setup
#| code-fold: false

import sys
import os
from dotenv import load_dotenv
from pathlib import Path

# Carrega .env e adiciona src ao path
load_dotenv()
sys.path.insert(0, os.getenv('PROJECT_ROOT') + '/src')

from config import PROJECT_ROOT, PATHS
from cleaning import run_pipeline, CLEANING_STEPS
from utils import format_audit_table, format_summary_table, generate_impact_analysis

# Define arquivos
RAW_FILE = PATHS['raw']
INTERIM_DIR = PATHS['interim']

print(f"üìÅ Projeto: {PROJECT_ROOT}")
print(f"üìÑ Arquivo de entrada: {RAW_FILE.name}")
print(f"üìÇ Diret√≥rio de sa√≠da: {INTERIM_DIR}")
```

# Data Cleaning

Com base nas descobertas documentadas no [Data Profiling](00-data-profiling.qmd), esta etapa implementa as transforma√ß√µes de limpeza necess√°rias para preparar o arquivo bruto para parsing e an√°lise.

## Objetivo

Transformar o arquivo bruto exportado do WhatsApp em um arquivo limpo e otimizado, removendo caracteres invis√≠veis, linhas vazias, normalizando espa√ßos e anonimizando participantes.

------------------------------------------------------------------------

## Configura√ß√£o e Execu√ß√£o do Pipeline

```{python}
#| label: pipeline-config
#| code-fold: false

# =============================================================================
# üîß CONFIGURA√á√ÉO DO PIPELINE
# 
# Para mudar a ordem: reordene os itens da lista
# Para remover etapa: remova o ID da lista
# Para ver etapas dispon√≠veis: print(list(CLEANING_STEPS.keys()))
#
# IDs dispon√≠veis:
#   - 'u200e'           : Remove caractere invis√≠vel U+200E
#   - 'empty_timestamps': Remove timestamps vazios (m√∫ltiplas m√≠dias)
#   - 'empty_lines'     : Remove linhas vazias
#   - 'whitespace'      : Normaliza espa√ßos internos
#   - 'anonymize'       : Anonimiza participantes (Marlon‚ÜíP1, L√™ üñ§‚ÜíP2)
#   - 'timestamps'      : Otimiza formato do timestamp
#   - 'indentation'     : Remove indenta√ß√£o de linhas de continua√ß√£o
# =============================================================================

PIPELINE_ORDER = [
    'u200e',
    'anonymize',
    'timestamps',
    'indentation',
    'empty_lines',
    'whitespace',
    'empty_timestamps',
]
```

```{python}
#| label: execute-pipeline

# Executa o pipeline
result = run_pipeline(
    order=PIPELINE_ORDER,
    raw_file=RAW_FILE,
    output_dir=INTERIM_DIR,
    show_progress=True
)

# Extrai resultados para uso posterior
outputs = result['outputs']
audits = result['audits']
metrics = result['metrics']
df_audit = result['df_audit']
totals = result['totals']
FINAL_OUTPUT = result['final_output']
```

------------------------------------------------------------------------

## Pipeline de Transforma√ß√£o

```{python}
#| label: render-pipeline
#| output: asis
#| echo: false

# Renderiza cada etapa como um accordion
for i, step_id in enumerate(PIPELINE_ORDER):
    step = CLEANING_STEPS[step_id]
    step_num = i + 1
    audit = audits[step_id]
    step_metrics = metrics[step_id]
    
    print(f'''<details style="margin: 0.5em 0; list-style: none; border: 1px solid #d4d4d4; border-radius: 5px; padding: 10px;">
<summary style="font-size: 1.3em; font-weight: 600; color: #343a40; list-style: none;">
‚ñ∏ Etapa {step_num}: {step['name']}
</summary>

**Sobre esta transforma√ß√£o:**

{step['description']}

---

**Resultado:**
''')
    
    # Mostra m√©tricas espec√≠ficas
    for key, value in step_metrics.items():
        if isinstance(value, dict):
            for k, v in value.items():
                print(f"- {k}: {v:,}")
        else:
            print(f"- {key.replace('_', ' ').title()}: {value:,}")
    
    # Mostra auditoria resumida
    print(f'''
**Auditoria:**

| M√©trica | Valor |
|---------|-------|
| Entrada | {audit['input']['size_formatted']} ({audit['input']['total_lines']:,} linhas) |
| Sa√≠da | {audit['output']['size_formatted']} ({audit['output']['total_lines']:,} linhas) |
| Redu√ß√£o | {audit['delta_bytes']:,} bytes ({audit['delta_percent']:.2f}%) |

</details>
''')
```

------------------------------------------------------------------------

## Auditoria Final do Pipeline

```{python}
#| label: prepare-audit-list
#| output: false

# Lista de audits na ordem do pipeline
audit_list = [audits[step_id] for step_id in PIPELINE_ORDER]
```

::: panel-tabset
## Compara√ß√£o de Est√°gios

```{python}
#| label: show-audit-table
#| echo: false

format_audit_table(df_audit, include_chars=True).style.hide(axis='index')
```

## Resumo por Etapa

```{python}
#| label: show-summary
#| echo: false

format_summary_table(audit_list).style.hide(axis='index')
```
:::

------------------------------------------------------------------------

::: {.callout-tip icon="false" collapse="false"}
## üéØ Resultado Final

```{python}
#| echo: false

print(f"üìÅ Arquivo original: {totals['original_formatted']}")
print(f"üìÅ Arquivo final: {totals['final_formatted']}")
print(f"üì¶ Redu√ß√£o total: {totals['total_bytes']:,} bytes ({totals['total_percent']:.2f}%)")
print(f"üìâ Linhas removidas: {totals['total_lines']:,}")
print(f"üî§ Caracteres removidos: {totals['total_chars']:,}")
print(f"‚úÖ Arquivo de sa√≠da: {FINAL_OUTPUT.name}")
```

O arquivo limpo est√° pronto para a pr√≥xima etapa: **parsing e estrutura√ß√£o em DataFrame**.
:::

------------------------------------------------------------------------

::: {.callout-note icon="false" collapse="false"}
## üìä Reflex√£o: Impacto no Dataset Enriquecido

```{python}
#| echo: false

impact = generate_impact_analysis(totals, enrichment_factor=8.0)

print(f"üìÅ Arquivo bruto:")
print(f"   ‚Ä¢ Original: {impact['original_mb']:.2f} MB")
print(f"   ‚Ä¢ Ap√≥s limpeza: {impact['final_mb']:.2f} MB")
print(f"   ‚Ä¢ Redu√ß√£o: {impact['reduction_pct']:.2f}%\n")

print(f"üìà Proje√ß√£o para dataset enriquecido (fator ~{impact['enrichment_factor']:.0f}x):")
print(f"   ‚Ä¢ Sem otimiza√ß√£o: ~{impact['projected_original_mb']:.1f} MB")
print(f"   ‚Ä¢ Com otimiza√ß√£o: ~{impact['projected_optimized_mb']:.1f} MB")
print(f"   ‚Ä¢ Economia projetada: ~{impact['projected_savings_mb']:.1f} MB\n")

print(f"üí° Cada caractere removido agora significa menos dados para:")
print(f"   ‚Ä¢ Armazenar em disco e mem√≥ria")
print(f"   ‚Ä¢ Processar em opera√ß√µes de NLP")
print(f"   ‚Ä¢ Transferir entre sistemas")
print(f"   ‚Ä¢ Incluir em embeddings e modelos")
```

A limpeza realizada nesta etapa n√£o apenas organiza os dados, mas **reduz significativamente o custo computacional** de todas as opera√ß√µes subsequentes.
:::

------------------------------------------------------------------------

## Arquivo de Sa√≠da

O arquivo final agora possui:

-   ‚úÖ Formato otimizado: `DD/MM/YY HH:MM:SS Remetente: Conte√∫do`
-   ‚úÖ Participantes anonimizados (P1, P2)
-   ‚úÖ Sem caracteres invis√≠veis
-   ‚úÖ Sem linhas/timestamps vazios
-   ‚úÖ Espa√ßos e indenta√ß√£o normalizados

::: {.callout-note appearance="simple" collapse="true"}
### üìã Regex para parsing do arquivo limpo

``` python
# Padr√£o para identificar in√≠cio de mensagem
message_pattern = r'^(\d{2}/\d{2}/\d{2}) (\d{2}:\d{2}:\d{2}) (.+?): (.*)$'

# Grupos de captura:
# 1: Data (DD/MM/YY)
# 2: Hora (HH:MM:SS)
# 3: Remetente (P1 ou P2)
# 4: Conte√∫do da mensagem
```
:::

------------------------------------------------------------------------

# Pr√≥ximos Passos

Com o arquivo limpo, seguimos para:

1.  [**Data Wrangling**](02-data-wrangling.qmd) ‚Äî Parsing, agrega√ß√£o de multilinha, vincula√ß√£o de m√≠dia
2.  [**Feature Engineering**](03-feature-engineering.qmd) ‚Äî Cria√ß√£o de vari√°veis derivadas