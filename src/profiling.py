"""
FunÃ§Ãµes de Data Profiling para investigaÃ§Ã£o de arquivos brutos.

Este mÃ³dulo fornece ferramentas para explorar e entender a estrutura
de arquivos de texto antes de iniciar o processo de limpeza.
"""

import re
import os
import pandas as pd
from typing import Optional


def get_file_overview(file_path: str) -> dict:
    """
    Retorna visÃ£o geral do arquivo com metadados bÃ¡sicos.
    
    Args:
        file_path: Caminho do arquivo
        
    Returns:
        Dict com mÃ©tricas do arquivo
    """
    size_bytes = os.path.getsize(file_path)
    
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    total_lines = len(lines)
    total_chars = sum(len(line) for line in lines)
    non_empty_lines = sum(1 for line in lines if line.strip())
    
    # EstatÃ­sticas de comprimento de linha
    line_lengths = [len(line) for line in lines]
    avg_line_length = sum(line_lengths) / len(line_lengths) if line_lengths else 0
    
    result = {
        'arquivo': file_path,
        'tamanho_bytes': size_bytes,
        'tamanho_formatted': format_bytes(size_bytes),
        'total_linhas': total_lines,
        'linhas_nao_vazias': non_empty_lines,
        'linhas_vazias': total_lines - non_empty_lines,
        'total_caracteres': total_chars,
        'media_chars_por_linha': round(avg_line_length, 1)
    }
    
    # Print formatado
    print("=" * 60)
    print("ğŸ“Š VISÃƒO GERAL DO ARQUIVO")
    print("=" * 60)
    print(f"ğŸ“„ Arquivo: {file_path}")
    print(f"ğŸ’¾ Tamanho: {result['tamanho_formatted']} ({size_bytes:,} bytes)")
    print(f"ğŸ“ Linhas: {total_lines:,} (vazias: {result['linhas_vazias']:,})")
    print(f"ğŸ”¤ Caracteres: {total_chars:,}")
    print(f"ğŸ“ MÃ©dia chars/linha: {avg_line_length:.1f}")
    print("=" * 60)
    
    return result


def format_bytes(size: int) -> str:
    """Formata bytes para unidade legÃ­vel."""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024:
            return f"{size:.2f} {unit}"
        size /= 1024
    return f"{size:.2f} TB"


def get_lines_at_position(file_path: str, position: int = 0, n: int = 5) -> pd.DataFrame:
    """
    Retorna n linhas de uma posiÃ§Ã£o percentual do arquivo.
    
    Args:
        file_path: Caminho do arquivo
        position: PosiÃ§Ã£o percentual (0-100)
        n: NÃºmero de linhas a retornar
        
    Returns:
        DataFrame com nÃºmero da linha e conteÃºdo
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    total_lines = len(lines)
    start_idx = int((position / 100) * total_lines)
    
    # Ajusta para nÃ£o ultrapassar o final
    start_idx = min(start_idx, total_lines - n)
    start_idx = max(0, start_idx)
    
    result = []
    for i in range(start_idx, min(start_idx + n, total_lines)):
        result.append({
            'linha': i + 1,
            'conteudo': lines[i].rstrip('\n')
        })
    
    return pd.DataFrame(result)


def get_lines_containing(file_path: str, substring: str, n: int = 5) -> pd.DataFrame:
    """
    Retorna n linhas que contÃªm o substring especificado.
    
    Args:
        file_path: Caminho do arquivo
        substring: Texto a buscar
        n: NÃºmero mÃ¡ximo de linhas a retornar
        
    Returns:
        DataFrame com nÃºmero da linha e conteÃºdo
    """
    matches = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f, 1):
            if substring in line:
                matches.append({
                    'linha': i,
                    'conteudo': line.rstrip('\n')
                })
                if len(matches) >= n:
                    break
    
    if not matches:
        print(f"âš ï¸ Nenhuma linha encontrada contendo: '{substring}'")
        return pd.DataFrame(columns=['linha', 'conteudo'])
    
    return pd.DataFrame(matches)


def get_lines_matching(file_path: str, pattern: str, n: int = 5) -> pd.DataFrame:
    """
    Retorna n linhas que casam com o padrÃ£o regex.
    
    Args:
        file_path: Caminho do arquivo
        pattern: PadrÃ£o regex
        n: NÃºmero mÃ¡ximo de linhas a retornar
        
    Returns:
        DataFrame com nÃºmero da linha e conteÃºdo
    """
    matches = []
    regex = re.compile(pattern)
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f, 1):
            if regex.search(line):
                matches.append({
                    'linha': i,
                    'conteudo': line.rstrip('\n')
                })
                if len(matches) >= n:
                    break
    
    if not matches:
        print(f"âš ï¸ Nenhuma linha encontrada com padrÃ£o: '{pattern}'")
        return pd.DataFrame(columns=['linha', 'conteudo'])
    
    return pd.DataFrame(matches)


def count_pattern(file_path: str, pattern: str) -> dict:
    """
    Conta ocorrÃªncias de um padrÃ£o no arquivo.
    
    Args:
        file_path: Caminho do arquivo
        pattern: PadrÃ£o regex ou string literal
        
    Returns:
        Dict com total de ocorrÃªncias e linhas afetadas
    """
    total = 0
    lines_with = 0
    
    # Tenta compilar como regex, senÃ£o usa como string literal
    try:
        regex = re.compile(pattern)
        use_regex = True
    except re.error:
        use_regex = False
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if use_regex:
                found = len(regex.findall(line))
            else:
                found = line.count(pattern)
            
            total += found
            if found > 0:
                lines_with += 1
    
    return {
        'total_ocorrencias': total,
        'linhas_com_pattern': lines_with
    }


def multi_position_preview(file_path: str, 
                           n_lines: int = 5, 
                           positions: list = [0, 25, 50, 75, 100]) -> pd.DataFrame:
    """
    Retorna preview do arquivo em mÃºltiplas posiÃ§Ãµes percentuais.
    
    Args:
        file_path: Caminho do arquivo
        n_lines: Linhas por posiÃ§Ã£o
        positions: Lista de posiÃ§Ãµes percentuais
        
    Returns:
        DataFrame consolidado com separadores entre posiÃ§Ãµes
    """
    all_previews = []
    
    for pos in positions:
        preview = get_lines_at_position(file_path, position=pos, n=n_lines)
        preview['posicao'] = f"{pos}%"
        all_previews.append(preview)
        
        # Adiciona linha separadora (exceto apÃ³s Ãºltima posiÃ§Ã£o)
        if pos != positions[-1]:
            separator = pd.DataFrame([{
                'linha': '...',
                'conteudo': 'â”€' * 50,
                'posicao': ''
            }])
            all_previews.append(separator)
    
    return pd.concat(all_previews, ignore_index=True)


def analyze_line_patterns(file_path: str) -> dict:
    """
    Analisa padrÃµes gerais das linhas do arquivo.
    
    Returns:
        Dict com estatÃ­sticas de padrÃµes encontrados
    """
    patterns = {
        'com_timestamp': 0,
        'sem_timestamp': 0,
        'vazias': 0,
        'com_midia_omitida': 0,
        'com_midia_anexada': 0,
        'com_emoji': 0,
        'com_link': 0
    }
    
    timestamp_pattern = re.compile(r'^\[?\d{2}/\d{2}/\d{2}')
    media_omitted = re.compile(r'(audio|image|video|sticker|GIF|document) omitted')
    media_attached = re.compile(r'<attached:')
    url_pattern = re.compile(r'https?://')
    
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            stripped = line.strip()
            
            if not stripped:
                patterns['vazias'] += 1
                continue
            
            if timestamp_pattern.match(line):
                patterns['com_timestamp'] += 1
            else:
                patterns['sem_timestamp'] += 1
            
            if media_omitted.search(line):
                patterns['com_midia_omitida'] += 1
            
            if media_attached.search(line):
                patterns['com_midia_anexada'] += 1
            
            if url_pattern.search(line):
                patterns['com_link'] += 1
            
            # Emoji: caracteres com ord > 127 (simplificado)
            if any(ord(c) > 127 for c in line):
                patterns['com_emoji'] += 1
    
    return patterns


def print_pattern_summary(file_path: str):
    """
    Imprime resumo formatado dos padrÃµes encontrados.
    """
    patterns = analyze_line_patterns(file_path)
    
    total = patterns['com_timestamp'] + patterns['sem_timestamp'] + patterns['vazias']
    
    print("=" * 60)
    print("ğŸ“Š RESUMO DE PADRÃ•ES DO ARQUIVO")
    print("=" * 60)
    print(f"\nğŸ“ Estrutura de linhas:")
    print(f"   â€¢ Com timestamp: {patterns['com_timestamp']:,} ({patterns['com_timestamp']/total*100:.1f}%)")
    print(f"   â€¢ Sem timestamp (continuaÃ§Ã£o): {patterns['sem_timestamp']:,} ({patterns['sem_timestamp']/total*100:.1f}%)")
    print(f"   â€¢ Vazias: {patterns['vazias']:,} ({patterns['vazias']/total*100:.1f}%)")
    
    print(f"\nğŸ“ MÃ­dias:")
    print(f"   â€¢ Omitidas: {patterns['com_midia_omitida']:,}")
    print(f"   â€¢ Anexadas: {patterns['com_midia_anexada']:,}")
    
    print(f"\nğŸ”— ConteÃºdo especial:")
    print(f"   â€¢ Com links: {patterns['com_link']:,}")
    print(f"   â€¢ Com emoji/caracteres especiais: {patterns['com_emoji']:,}")
    print("=" * 60)
